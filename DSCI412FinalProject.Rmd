---
title: "DSCI412FinalProject"
author: "Joey Matte"
date: "2025-03-09"
output:
  word_document: default
  html_document: default
---
# Final Course Project

## 1. Data Preperation
### a. load the insurance.csv dataset. 
```{r}
data = read.csv('insurance.csv')
summary(data)
```

### b. In the data frame, log transform the variable charges and name it as log_charges.
```{r}
data$log_charges = log(data$charges)
```

### c. Use the sample () function with set.seed equal to 1 to generate row indexes for your training and tests sets, with 70% of the row indexes for your training set and 30% for your test set. Do not use any method other than the sample () function for splitting your data. 
```{r}
set.seed(1)
index = sample(1:nrow(data),nrow(data)*.7)
train = data[index,]
test = data[-index,]
```

## 2. Build a multiple regression model
### a. Perform multiple linear regression with log_charges as the response and the predictors are age, sex, bmi, children, smoker, and region. Print out the results using the summary () function. Use the training dataset you created in #1 above. 
```{r}
mulRegressModel = lm(log_charges~age+sex+bmi+children+smoker+region,data=train)
summary(mulRegressModel)
```

### b. Is there a relationship between the predictors and the response?
There is a relationship between the predictors and the response. All predictors have a p-value less than 0.05, which shows a relationship between them and the response variable.

### c. Does sex have a statistically significant relationship to the response? 
Sex has a p-value of 0.041, which is less than 0.05, meaning it has a statistically significant relationship to the response variable.

### d. Compare the test error of the model in #2a. Report the RMSE. 
```{r}
predictions1=predict(mulRegressModel,newdata=test)
mse1 = mean((predictions1-test[,'log_charges'])^2)
rmse1=mse1**.5
rmse1
```
The model has a RMSE of 0.4891.

## 3. Build a regression tree model
### a. Build a regression tree model using function tree (), where log_charges is the response and the predictors are age, sex, bmi, children, smoker, and region. 
```{r}
library(tree)
treeModel = tree(log_charges~age+sex+bmi+children+smoker+region,data=train)
```
### b. Find the optimal tree and display the results in a graphic. Report the best size. 
```{r}
cv.treeModel = cv.tree(treeModel)
plot(cv.treeModel$size,cv.treeModel$dev)
```

The best size for the model is 3.

### c. Justify the number you picked for the optimal tree with regard to the principle of the variance-bias trade-off. 
We want to keep the model as simple as possible while maintaining a high level of accuracy. When going from size 3 to 4, the accuracy does not change much, so the best option is size 3.

### d. Prune the tree using the optimal size found in 3.b.
```{r}
prune.treeModel = prune.tree(treeModel,best=3)
```
### e. Plot the best tree model and give labels. 
```{r}
plot(prune.treeModel)
text(prune.treeModel,pretty=0)
```

### f. Calculate the best RMSE for the best model. 
```{r}
predictions2=predict(prune.treeModel,newdata=test)
mse2 = mean((predictions2-test[,'log_charges'])^2)
rmse2=mse2**.5
rmse2
```
The RMSE for the model is 0.8425.

## 4. Build a random forest model
### a. Build a random forest model using function randomForest(), where log_charges is the response and the predictors are age, sex, bmi, children, smoker, and region.
```{r}
library(randomForest)
rfModel = randomForest(log_charges~age+sex+bmi+children+smoker+region,data=train)
```
### b. Compute the test error (using the test data set).
```{r}
predictions3=predict(rfModel,newdata=test)
mse3 = mean((predictions3-test[,'log_charges'])^2)
rmse3=mse3**.5
rmse3
```
The RMSE of the model is 0.4309.

### c. Extract variable importance measure using the importance() function.
```{r}
importance(rfModel)
```
### d. Plot the variable importance using the function, varImpPlot(). Which are the top 3 important predictors in this model?
```{r}
varImpPlot(rfModel)
```

Based on the graph, the top 3 most important predictors in this model are smoker, age, and bmi.

## 5. Perform the k-means cluster analysis
### a. Remove the sex, smoker, and region, since they are not numerical values.
```{r}
# also dropping charges here because I kept the column when making a new column for log_charges.
df = subset(data, select = -c(sex,smoker,region,charges))
head(df)
```

### b. Determine the optimal number of clusters. Justify your answer.
```{r}
library(factoextra)
library(cluster)
library(ggplot2)

fviz_nbclust(df,kmeans,method='gap_stat')
```

From the plot, we can see that the optimal number of clusters is 2.

### c. Perform k-means clustering using the optimal number of clusters from 5b.
```{r}
df_kmeans = kmeans(df,2,nstart=25)
```

### d. Visualize the clusters in different colors.
```{r}
fviz_cluster(df_kmeans,data=df)
```

## 6. Putting it all together
### a. For predicting insurance charges, your supervisor asks you to choose the best model among the multiple regression, regression tree, and random forest. Compare their test RMSEs of the models generated above. Display the names for these types of these models, using these labels: Multiple Linear Regression, Regression Tree, and Random Forest and their corresponding test RMSEs in a data.frame. Label the column in your data frame with the labels as Model.Type, and label the column with the test RMSEs as Test.MSE and round the data in this column to 4 decimal places. Present the formatted data to your supervisor and recommend which model is best and why.
```{r}
Model.Type=c('Multiple Linear Regression','Regression Tree','Random Forest')
Test.MSE=round(c(rmse1,rmse2,rmse3),4)
mseFrame = data.frame(Model.Type,Test.MSE)
mseFrame
```

I would recommended the Random Forest model because it has the lowest RMSE. This means it's predictions are the most accurate.

### b. Another supervisor from the sales department has requested your help to create a predictive model that his sales representatives can use to explain to clients what the potential costs could be for different kinds of customers, and they need an easy and visual way of explaining it. What model would you recommend, and what are the benefits and disadvantages of your recommended model compared to other models?

I would recommend the Regression Tree Model. The benefits of this model are that it is very easy to explain visually, and can be interpreted by non experts. The disadvantage is it is not as accurate as the other two models.

### c. The supervisor from the sales department likes your regression tree model. But she says that the salespeople say the numbers in it are way too low and suggests that maybe the numbers on the leaf nodes predicting charges are log transformations of the actual charges. You realize that in step 1.b of this project that you had indeed transformed charges using the log function. And now you realize that you need to reverse the transformation in your final output. The solution you have is to reverse the log transformation of the variables in the regression tree model you created and re display the result.

```{r}
copyPruneTreeModel = prune.tree(treeModel,best=3)
copyPruneTreeModel$frame$yval = exp(copyPruneTreeModel$frame$yval)
plot(copyPruneTreeModel)
text(copyPruneTreeModel,pretty=0)
```











